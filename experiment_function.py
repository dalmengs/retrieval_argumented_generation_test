import asyncio
from embedder import embedding
from Util.AsyncHttpRequest import Request
from Util.EnvironmentVariable import env

API_MODEL = env("OPENAI_MODEL")
API_KEY = env("OPENAI_API_KEY")

# [방법 1] 여러 개의 요약을 한 문장으로
async def aggregated_sentence_vector(sentences: list[str]) -> list[float]:
    embedded_vector = embedding(" ".join(sentences))
    return embedded_vector

# [방법 2] 세 벡터의 평균을 임베딩 벡터로 
async def averaged_sentence_vector(sentences: list[str]) -> list[float]:
    embedded_vector = embedding(sentences)
    averaged_vector = sum(embedded_vector) / len(embedded_vector)
    return averaged_vector

# [방법 3] 가중치를 부여하도록
async def weighted_sentence_vector(conversation: str, sentences: list[str]) -> list[float]:
    embedded_vector = embedding(sentences)

    messages = [
        {
            "role": "system",
            "content": "Your role is to allocate weights to sentences about their relevance."
        },
        {
            "role": "user",
            "content": """You are given conversation data and three summaries of this conversation.
I am planning to create a weighted embedding vector with these summaries to retrieve contextual relevance using cosine similarity. Therefore, you need to assign weights to the three summaries based on their relevance to the conversation. The creteria of relevance is "value as information.""
The output should be a Python list and its length must be equal to the length of summaries. Each element of the list should be a float. The sum of the elements in the output list must be 1, though the number of decimal places for each element can vary (up to 16 decimal places). For example, if all summaries are equally important, the output could be [0.3333333333333333, 0.3333333333333333, 0.3333333333333334], but the values will differ based on the importance of each summary.
Just print out output only, without any prose.

[Conversation]
{}

[summares]
{}
""".format(conversation, sentences)
        }
    ]

    response = await Request.post(
        url='https://api.openai.com/v1/chat/completions',
        headers={
            'Content-Type': 'application/json',
            "Authorization": f"Bearer {API_KEY}"
        },
        data={
            "model": API_MODEL,
            "messages": messages,
        }
    )
    response = response.json()["choices"][0]["message"]["content"]

    # Generated by GPT-4o
    def parse_list(s: str) -> list[float]:
        start_index = s.find('[')
        end_index = s.find(']')
        if start_index == -1 or end_index == -1 or start_index > end_index:
            raise ValueError("Invalid input string: missing or misplaced '[' or ']'")
        content = s[start_index + 1:end_index].strip()
        elements = content.split(',')
        result = [float(elem.strip()) for elem in elements]
        
        return result
    
    weights = parse_list(response)

    weighted_vector = sum([weights[i] * embedded_vector[i] for i in range(3)])
    return weighted_vector

# [방법 4] 언어 모델에게 선택하도록
async def model_choose_sentence_vector(conversation: str, sentences: list[str]):
    messages = [
        {
            "role": "system",
            "content": "Your role is to choose the most valuable information."
        },
        {
            "role": "user",
            "content": """You are given conversation data and three summaries of this conversation.
I am planning to create a embedding vector choosing only one among these summaries to retrieve contextual relevance using cosine similarity. Therefore, you need to pick one summary based on their relevance to the conversation and value as information."
The output is single integer, that is index of summaries. (e.g. 0, 1, 2)
Just print out output only, without any prose.

[Conversation]
{}

[summares]
{}
""".format(conversation, sentences)
        }
    ]

    response = await Request.post(
        url='https://api.openai.com/v1/chat/completions',
        headers={
            'Content-Type': 'application/json',
            "Authorization": f"Bearer {API_KEY}"
        },
        data={
            "model": API_MODEL,
            "messages": messages,
        }
    )
    response = response.json()["choices"][0]["message"]["content"]
    embedded_vector = embedding(sentences[int(response)])
    return embedded_vector

# [방법 5] 대화 자체를 임베딩
async def conversation_vector(conversation: str):
    embedded_vector = embedding(conversation)
    return embedded_vector

# [방법 6] 대화를 글로 변환 
async def conversation_public_vector(conversation: str):
    messages = [
        {
            "role": "user",
            "content": """I'll show you a conversation. Please analyze each utterance in order and convert the conversation into an analysis according to the following criteria:

First, mention the main topic of the conversation (e.g., They discussed about OOO).
Next, describe the new information mentioned in the conversation in order, summarizing it in a way that maintains the flow of the dialogue (e.g., Naly asked User's favorite food, User replied that his favorite food is hamburger).
Do not create sentences from greetings or interjections that lack informational value. Emphasize the events and emotional changes mentioned.
To increase embedding accuracy, present the output as a continuous string of sentences without any symbols.

Here is the conversation between User and Naly:
{}
""".format(conversation)
        }
    ]

    response = await Request.post(
        url='https://api.openai.com/v1/chat/completions',
        headers={
            'Content-Type': 'application/json',
            "Authorization": f"Bearer {API_KEY}"
        },
        data={
            "model": API_MODEL,
            "messages": messages,
        }
    )
    response = response.json()["choices"][0]["message"]["content"]
    embedded_vector = embedding(response.strip("`").strip("\"").strip())
    return embedded_vector
